import os
import h5py
import numpy as np
import datetime
import json
import re
from typing import Dict, Any, Union, Optional
import re
import Labber
import math


def hdf5_generator(
    filepath: str,
    x_info: dict,
    z_info: dict,
    y_info: dict = None,
    comment=None,
    tag=None,
):
    np.float = float
    np.bool = bool
    zdata = z_info["values"]
    z_info.update({"complex": True, "vector": False})

    log_channels = [z_info]
    step_channels = list(filter(None, [x_info, y_info]))

    fObj = Labber.createLogFile_ForData(filepath, log_channels, step_channels)
    if y_info:
        for trace in zdata:
            fObj.addEntry({z_info["name"]: trace})
    else:
        fObj.addEntry({z_info["name"]: zdata})

    if comment:
        fObj.setComment(comment)
    if tag:
        fObj.setTags(tag)


def update_python_dict(
    file_path: str, updates: Dict[str, Union[Any, Dict[int, Any]]]
) -> None:
    """
    Update dictionary values inside a Python config file while preserving formatting and comments.

    Supports updating specific indices in lists instead of overwriting the entire list.

    Args:
        file_path (str): Path to the Python configuration file.
        updates (Dict[str, Union[Any, Dict[int, Any]]]): Dictionary of updates.
            - Example 1: {"readout_cfg.mixer_freq": 5800}  (Normal update)
            - Example 2: {"qubit_cfg.qubit_freq_ge": {2: 4500}}  (Update list index 2)

    Returns:
        None
    """
    with open(file_path, "r", encoding="utf-8") as f:
        lines = f.readlines()

    new_lines = []
    # Track which dictionary we are modifying
    inside_target: Optional[str] = None

    for line in lines:
        stripped = line.strip()
        modified = False

        # Detect dictionary entry
        for full_key, new_value in updates.items():
            # "qubit_cfg.qubit_freq_ge" → ("qubit_cfg", "qubit_freq_ge")
            dict_name, key = full_key.split(".", 1)

            if stripped.startswith(f"{dict_name} = {{"):
                inside_target = dict_name

            # Only process lines inside the target dictionary
            if inside_target and re.match(rf'^\s*"{key}"\s*:\s*', stripped):
                if isinstance(new_value, dict):  # If updating a list index
                    match = re.search(rf'"{key}"\s*:\s*(\[[^\]]*\])', stripped)
                    if match:
                        # Convert text to Python list
                        old_list = eval(match.group(1))
                        for idx, val in new_value.items():
                            if 0 <= idx < len(old_list):
                                # Update only the specified index
                                old_list[idx] = val
                        new_list_str = str(old_list).replace(
                            "'", ""
                        )  # Format correctly
                        line = re.sub(
                            rf'"{key}"\s*:\s*\[[^\]]*\]',
                            f'"{key}": {new_list_str}',
                            line,
                        )

                else:  # Normal value update
                    line = re.sub(
                        rf'("{key}"\s*:\s*)[^,]*',
                        lambda m: f"{m.group(1)}{new_value}",
                        line,
                    )

        new_lines.append(line)

        # Exit dictionary when closing `}`
        if inside_target and stripped == "}":
            inside_target = None

    # Write back to file
    with open(file_path, "w", encoding="utf-8") as f:
        f.writelines(new_lines)


def select_config_idx(config: dict, idx: int) -> dict:
    selected = {}
    for key, value in config.items():
        if isinstance(value, list):
            if idx < len(value):
                selected[key] = value[idx]
            else:
                raise IndexError(f"Index {idx} out of range for key '{key}'")
        else:
            selected[key] = value
    return selected


def get_next_filename(base_path: str, exp_name: str, suffix: str = ".h5") -> str:
    """
    Generate a unique filename for an experiment, ensuring no duplicates.

    Args:
        base_path (str): Base directory for saving the file.
        exp_name (str): Experiment name.
        suffix (str): File extension, default is ".h5".

    Returns:
        str: The next available filename.
    """
    today = datetime.date.today()
    year, month, day = today.strftime("%Y"), today.strftime("%m"), today.strftime("%d")
    date_path = f"{month}-{day}"  # Format MM-DD

    experiment_path = os.path.join(base_path, year, month, date_path)
    os.makedirs(experiment_path, exist_ok=True)

    i = 1
    while True:
        fname = f"{exp_name}_{i}{suffix}"
        full_path = os.path.join(experiment_path, fname)
        if not os.path.exists(full_path):
            return full_path
        i += 1



def get_next_filename_labber(
    dest_path: str, exp_name: str, yoko_value: Optional[Dict[str, Any]] = None
) -> str:
    """
    Generates the next HDF5 filename.

    - If yoko_value is provided, returns a name based on that value.
    - If yoko_value is None, recursively searches dest_path for the
      highest index (exp_name_NNN.hdf5) and returns the next one.

    Files are saved in the directory for the current date.
    """

    # 1. Ensure dest_path is absolute and create today's save directory
    dest_path = os.path.abspath(dest_path)
    yy, mm, dd = datetime.datetime.today().strftime("%Y-%m-%d").split("-")
    save_path = os.path.join(dest_path, yy, mm, f"Data_{mm}{dd}")
    os.makedirs(save_path, exist_ok=True)

    # 2. Check Yoko mode.
    if yoko_value is not None:
        # Yoko mode: use the provided value and unit for the name.
        # This logic does NOT use an incrementing index.
        try:
            value = yoko_value["value"]
            value = auto_unit(value)
            unit = yoko_value["unit"]
            filename = f"{exp_name}_{value['value']:.2f}{value['unit']}{unit}"
            return os.path.join(save_path, filename)
        except KeyError:
            # Handle cases where the dictionary is malformed
            raise ValueError(
                "yoko_value dictionary must contain 'value' and 'unit' keys"
            )

    else:
        # 3. Normal (index) mode: Find the next available index recursively.
        max_index = 0

        # Regex to find files matching "exp_name_NNN.hdf5"
        # This will *only* match files from the normal (non-yoko) mode.
        pattern = re.compile(rf"^{re.escape(exp_name)}_(\d+)$")

        # *** Core Change: Use os.walk to search all subdirectories ***
        for root, dirs, files in os.walk(dest_path):
            for f in files:
                match = pattern.match(f)
                if match:
                    # match.group(1) is the number (e.g., '001')
                    current_index = int(match.group(1))
                    if current_index > max_index:
                        max_index = current_index

        # 4. Calculate the next index
        next_index = max_index + 1

        # 5. Return the new filename, formatted to 3 digits (e.g., _001, _002)
        final_filename = f"{exp_name}_{next_index:03d}"
        return os.path.join(save_path, final_filename)


def saveh5(
    file_path: str,
    data_dict: Dict[str, Any],
    config: Optional[Dict[str, Any]] = None,
    result: Optional[Dict[str, Any]] = None,
) -> None:
    """
    Save experiment data to an HDF5 file.

    Args:
        file_path (str): Path to save the HDF5 file.
        data_dict (Dict[str, Any]): Data to be stored.
        config (Optional[Dict[str, Any]]): Configuration parameters.
        result (Optional[Dict[str, Any]]): Experimental results.
    """
    with h5py.File(file_path, "w") as f:
        param_grp = f.create_group("parameter")
        data_grp = f.create_group("data")

        if "x_name" in data_dict and "x_value" in data_dict:
            x_grp = param_grp.create_group(data_dict["x_name"])
            x_grp.create_dataset("x_axis_value", data=data_dict["x_value"])

        if "y_name" in data_dict and "y_value" in data_dict:
            y_grp = param_grp.create_group(data_dict["y_name"])
            y_grp.create_dataset("y_axis_value", data=data_dict["y_value"])

        if "z_name" in data_dict and "z_value" in data_dict:
            data_grp.create_dataset(data_dict["z_name"], data=data_dict["z_value"])
        if "experiment_name" in data_dict:
            f.attrs["experiment_name"] = data_dict["experiment_name"]
        if config:
            f.attrs["config"] = json.dumps(config)
        if result:
            f.attrs["result"] = json.dumps(result)


def saveshot(
    file_path: str,
    data_dict: Dict[str, Any],
    config: Optional[Dict[str, Any]] = None,
    result: Optional[Dict[str, Any]] = None,
) -> None:
    """
    Save experiment data to an HDF5 file.

    Args:
        file_path (str): Path to save the HDF5 file.
        data_dict (Dict[str, Any]): Data to be stored.
        config (Optional[Dict[str, Any]]): Configuration parameters.
        result (Optional[Dict[str, Any]]): Experimental results.
    """
    with h5py.File(file_path, "w") as f:
        data_grp = f.create_group("data")

        for key, value in data_dict.items():
            data_grp.create_dataset(key, data=value)

        if "experiment_name" in data_dict:
            f.attrs["experiment_name"] = data_dict["experiment_name"]
        if config:
            f.attrs["config"] = json.dumps(config)
        if result:
            f.attrs["result"] = json.dumps(result)


def read_h5_file(file_path: str) -> Dict[str, Any]:
    """
    Read experiment data from an HDF5 file.

    Args:
        file_path (str): Path to the HDF5 file.

    Returns:
        Dict[str, Any]: Dictionary containing x_name, x_value, y_name
        (if available), y_value (if available), z_value, config (if available), and result (if available).
    """
    data = {}

    with h5py.File(file_path, "r") as f:
        param_grp = f["parameter"]
        data_grp = f["data"]

        x_name, y_name = None, None
        x_value, y_value = None, None

        # Identify which key contains x_axis_value and y_axis_value
        for key in param_grp.keys():
            subgroup = param_grp[key]
            if "x_axis_value" in subgroup:
                x_name = key
                x_value = subgroup["x_axis_value"][:]
            elif "y_axis_value" in subgroup:
                y_name = key
                y_value = subgroup["y_axis_value"][:]

        # Ensure x_name and x_value exist
        if x_name and x_value is not None:
            data["x_name"] = x_name
            data["x_value"] = np.asarray(x_value)
        else:
            raise ValueError("No x-axis data found in the HDF5 file.")

        # Store y-axis data if available
        if y_name and y_value is not None:
            data["y_name"] = y_name
            data["y_value"] = np.asarray(y_value)
        else:
            data["y_name"] = None
            data["y_value"] = None

        # Extract z-axis data
        z_name = next(iter(data_grp.keys()), None)
        if z_name:
            data["z_name"] = z_name
            data["z_value"] = np.asarray(data_grp[z_name][:])
        else:
            raise ValueError("No z-axis data found in the HDF5 file.")

        # Extract config and result if available
        data["experiment_name"] = (
            json.loads(f.attrs["experiment_name"])
            if "experiment_name" in f.attrs
            else None
        )
        data["config"] = json.loads(f.attrs["config"]) if "config" in f.attrs else None
        data["result"] = json.loads(f.attrs["result"]) if "result" in f.attrs else None

    return data


def auto_unit(value, base_unit=""):
    prefixes = {
        -12: "p",  # pico
        -9: "n",  # nano
        -6: "u",  # micro
        -3: "m",  # milli
        0: "",  # base
        3: "k",  # kilo
        6: "M",  # mega
        9: "G",  # giga
    }

    arr = np.array(value, dtype=float)

    maxval = np.max(np.abs(arr))
    if maxval == 0:
        exp = 0
    else:
        exp = int(math.floor(math.log10(maxval) / 3) * 3)
        exp = max(min(exp, 9), -12)

    scaled_value = arr / (10**exp)
    prefix = prefixes[exp]

    return {"unit": f"{prefix}{base_unit}", "value": scaled_value}


if __name__ == "__main__":
    # 設定實驗名稱與路徑
    BASE_PATH = "data"
    exp_name = "Experiment_Q1"
    file_path = get_next_filename(BASE_PATH, exp_name)

    data_dict = {
        "x_name": "x_axis",
        "x_value": np.linspace(0, 10, 5),
        "y_name": "y_axis",
        "y_value": np.linspace(0, 20, 4),
        "z_name": "iq_list",
        "z_value": np.outer(
            np.sin(np.linspace(0, 10, 5)), np.cos(np.linspace(0, 20, 4))
        ),
    }

    config = {"ro_ch": 0, "res_ch": 0}

    result = {"T1": "350us", "T2": "130us"}

    saveh5(file_path, data_dict, config, result)
    print(f"Data saved to: {file_path}")

    # # 讀取 HDF5 檔案
    # loaded_data = readh5(r'F:\CODE\tprocv2_scrip\data\2025\02\02-03\Experiment_Q1_9.h5')
    # print("Loaded Data:", loaded_data)

    # # idx = 3
    # # selected_config = select_config_idx(readout_cfg, qubit_cfg, idx=idx)
    # # pprint(selected_config)

    # QubitIndex = 4
    # config = select_config_idx(readout_cfg, qubit_cfg, idx=QubitIndex)
    # # Update parameters to see TOF pulse with your setup
    # config.update([('res_freq', 7100), ('res_gain', 0.8), ('res_length', 0.5), ('ro_length', 1.5)])
    # pprint(config)

    # **示例：更新 readout_cfg["ro_length"] 和 qubit_cfg["qubit_freq_ge"]**
    # updates = {
    #     'readout_cfg["ro_length"]': "2.0",
    #     'qubit_cfg["qubit_freq_ge"]': "[4500, 4600, 4700, 4800, 4900, 5100]"
    # }

    # update_python_dict(config_file, updates)
    # print("Config updated successfully!")
